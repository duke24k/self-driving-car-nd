{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv, random, numpy as np\n",
    "from keras.models import load_model, Sequential,model_from_json\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Cropping2D\n",
    "from keras.preprocessing.image import img_to_array, load_img, flip_axis, random_shift\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from math import floor\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define Model Architecture\n",
    "adam optimizer configuration is default on Keras document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(load, shape, lr = 0.001, checkpoint=None):\n",
    "    \"\"\"Return a model from file or to train on.\"\"\"\n",
    "    \n",
    "   \n",
    "    \n",
    "    if load and checkpoint: return load_model(checkpoint)\n",
    "\n",
    "#    conv_layers1, conv_layers2, dense_layers = [24, 36, 48], [64, 64], [1024, 512]\n",
    "    dense_layers = [1024, 512]\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Cropping2D(cropping=((40,20), (20,20)), input_shape=shape))\n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5))\n",
    "\n",
    "    model.add(Convolution2D(24,5, 5,  border_mode = 'same',subsample=(1, 1)))\n",
    "    model.add(ELU())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "      \n",
    "    model.add(Convolution2D(32,5, 5,  border_mode = 'same', subsample=(1, 1),activation='elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(48,3, 3, border_mode = 'same', subsample=(1, 1),activation='elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3,  border_mode = 'same', subsample=(1, 1), activation='elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    for dl in dense_layers:\n",
    "        model.add(Dense(dl, activation='elu'))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=adam)\n",
    "    \n",
    "    print(\"adam optimizer, lr is %s\" % lr)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define how to downsample \n",
    "Define steering angle offset for left and right side camera images.\n",
    "- 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_X_y(labels, device='linux', desc='left'):\n",
    "  \n",
    "    X, y = [], []\n",
    "    base = []\n",
    "\n",
    "    steering_offset = 0.35\n",
    "    with open(labels) as fin:\n",
    "        for center_img, left_img, right_img, steering_angle, _, _, speed in csv.reader(fin):\n",
    "            \n",
    "      \n",
    "                        left_img = left_img.split('/')[-1]\n",
    "                        right_img = right_img.split('/')[-1]\n",
    "                        center_img = center_img.split('/')[-1]\n",
    "        \n",
    "                        X += [left_img.strip()]\n",
    "                        y += [float(steering_angle) + steering_offset]\n",
    "                \n",
    "                        X += [right_img.strip()]\n",
    "                        y += [float(steering_angle) - steering_offset]\n",
    "                        \n",
    "                   \n",
    "                        X += [center_img.strip()]\n",
    "                        y += [float(steering_angle)]\n",
    "                        \n",
    "        \n",
    "                        shuffle(X, y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Data\n",
    "- data_dir1 : data udacity provides for the project\n",
    "- t1_re : recovery data for the problem part of track1 on left turn. recored on linux\n",
    "- t1_rer : recovery data for the problem part of track1  on reverse, right, turn. recored on linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir1 = ('../../../data2/driving_log.csv','linux','left')\n",
    "#t1_re=('../t1_re/driving_log.csv','linux','re_left')\n",
    "#t1_rer=('../t1_rer/driving_log.csv','linux','re_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge_data(dir1, dir2, dir3):\n",
    "\n",
    "    X1, y1 = get_X_y(dir1[0], device=dir1[1], desc=dir1[2])\n",
    "    \n",
    "    X2, y2 = get_X_y(dir2[0], device=dir2[1], desc=dir2[2])\n",
    "    \n",
    "    X3, y3 = get_X_y(dir3[0], device=dir3[1], desc=dir3[2])\n",
    "    \n",
    "   \n",
    "    X = X1 + X2 + X3\n",
    "    y =  y1 + y2 + y3\n",
    "    \n",
    "\n",
    "    return X,y\n",
    "\n",
    "def merge_udacity_data(dir1):\n",
    "\n",
    "    X1, y1 = get_X_y(dir1[0], device=dir1[1], desc=dir1[2])\n",
    "      \n",
    "    X = X1 \n",
    "    y =  y1 \n",
    "    \n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data points 24108 \n",
      "mean value of the data 0.00406964406483 \n"
     ]
    }
   ],
   "source": [
    "#X_raw, y_raw = merge_data(data_dir1, t1_re, t1_rer)\n",
    "\n",
    "X_raw, y_raw = merge_udacity_data(data_dir1)\n",
    "    \n",
    "print(\"total data points %s \" % len(y_raw))\n",
    "\n",
    "print(\"mean value of the data %s \" %  np.mean(np.array(y_raw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "subsampling data.\n",
    "https://github.com/jeremy-shannon/CarND-Behavioral-Cloning-Project/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f3eddafa780>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1P8H2LZH6Vn+vfsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3edfdb6278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_np = np.array(y_raw)\n",
    "num_bins = 23\n",
    "avg_samples_per_bin = len(y_np)/num_bins\n",
    "\n",
    "hist, bins = np.histogram(y_np, num_bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.plot((np.min(y_np), np.max(y_np)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "\n",
    "plt.title('total data distribution, 23bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5690412122928763, 0.0961980463512737, 0.40880417825408666, 0.46215780998389688, 0.097305413390593967, 0.40976306217493286, 0.43277205327971852, 0.10039980009995003, 0.53369343841317629, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def make_keep_probs(target):\n",
    "    \n",
    "    keep_probs = []\n",
    "    \n",
    "    for i in range(num_bins):\n",
    "        if hist[i] < target:\n",
    "            keep_probs.append(1.)\n",
    "        else:\n",
    "            keep_probs.append(1./(hist[i]/target))\n",
    "            \n",
    "    return keep_probs\n",
    "\n",
    "keep_probs = make_keep_probs(avg_samples_per_bin * .5)\n",
    "\n",
    "print(keep_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_remove_list(angles, keep_probs, left_cut = 2.5, right_cut = 2.5, center_cut= 0.7):\n",
    "    \n",
    "    remove_list = []\n",
    "    for i in range(len(angles)):\n",
    "        for j in range(num_bins):\n",
    "            if angles[i] > bins[j] and angles[i] <= bins[j+1]:\n",
    "            # delete from X and y with probability 1 - keep_probs[j]\n",
    "            \n",
    "                if j > (num_bins/2 - left_cut) and j < (num_bins/2 + right_cut):\n",
    "                \n",
    "                    if np.random.rand() > (keep_probs[j] * center_cut) :\n",
    "                    \n",
    "                        remove_list.append(i)\n",
    "            \n",
    "                else:\n",
    "            \n",
    "                    if np.random.rand() > keep_probs[j]:\n",
    "                        remove_list.append(i)\n",
    "    \n",
    "    return remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00406964406483\n",
      "0.313471474417\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f445c4ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 23\n",
    "avg_samples_per_bin = len(y_np)/num_bins\n",
    "hist, bins = np.histogram(y_np, num_bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.plot((np.min(y_np), np.max(y_np)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "\n",
    "print(np.mean(y_np))\n",
    "print(np.std(y_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keep_probs = make_keep_probs(avg_samples_per_bin * .5)\n",
    "remove_list = make_remove_list(angles = y_np, keep_probs= keep_probs, left_cut = 2.5, right_cut = 2.5)\n",
    "\n",
    "angles_np = np.delete(y_np, remove_list)\n",
    "\n",
    "X_np = np.array(X_raw)\n",
    "images_np = np.delete(X_np, remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "angles = angles_np.tolist()\n",
    "images = images_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0166484662112\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3edda6b940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 23\n",
    "\n",
    "hist, bins = np.histogram(angles, num_bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "\n",
    "\n",
    "print(np.mean(angles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define how to do data augmentation\n",
    "- random_darken\n",
    "- vertical shift\n",
    "- horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def random_darken(image):\n",
    "    \"\"\"Given an image (from Image.open), randomly darken a part of it.\"\"\"\n",
    "    w, h = image.size\n",
    "\n",
    "    # Make a random box.\n",
    "    x1, y1 = random.randint(0, w), random.randint(0, h)\n",
    "    x2, y2 = random.randint(x1, w), random.randint(y1, h)\n",
    "\n",
    "    # Loop through every pixel of our box (*GASP*) and darken.\n",
    "    for i in range(x1, x2):\n",
    "        for j in range(y1, y2):\n",
    "            new_value = tuple([int(x * 0.5) for x in image.getpixel((i, j))])\n",
    "            image.putpixel((i, j), new_value)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, label, split = 0.3):\n",
    "    \n",
    "    train_samples, validation_samples, train_labels, validation_labels = train_test_split(\n",
    "    data,\n",
    "    label,\n",
    "    test_size=split,\n",
    "    random_state=832289)\n",
    "    \n",
    "    return train_samples, validation_samples, train_labels, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image_test(image, steering_angle, augment=True, shape=(160,320)):\n",
    "    \"\"\"Process and augment an image.\"\"\"\n",
    "\n",
    "    pil_image = Image.fromarray(image)\n",
    "\n",
    "    if augment and random.random() < 0.5:\n",
    "        pil_image = random_darken(pil_image)  # before numpy'd\n",
    "\n",
    "    image = img_to_array(pil_image)\n",
    "        \n",
    "    if augment:\n",
    "        image = random_shift(image, 0.0, 0.2, 0, 1, 2)  # only vertical\n",
    "        if random.random() < 0.5:\n",
    "            image = flip_axis(image, 1)\n",
    "            steering_angle = -steering_angle\n",
    "\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define generator \n",
    "\n",
    "- generator : train generator\n",
    "- generator_valid : validation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# image directory, path = '../merge_image/image/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_path = '../../../merge_image/image/'\n",
    "\n",
    "def generator(samples, labels, batch_size=128, model='default'):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples, labels)\n",
    "        \n",
    "        print('\\n training batch shuffled')\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "           \n",
    "        #    print(type(samples))\n",
    "        #    print(len(samples))\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            batch_labels = labels[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for idx, val in enumerate(batch_samples):\n",
    "\n",
    "        \n",
    "                name = batch_samples[idx]\n",
    "                \n",
    "                path = image_path + name \n",
    "            \n",
    "          #      raw_image = cv2.imread(path)\n",
    "        \n",
    "                srcBGR = cv2.imread(path)\n",
    "          #      destRGB = cv2.cvtColor(srcBGR, cv2.COLOR_BGR2RGB)\n",
    "               \n",
    "                new_img = cv2.cvtColor(srcBGR , cv2.COLOR_BGR2YUV)\n",
    "                    \n",
    "                raw_angle = float(batch_labels[idx])\n",
    "                \n",
    "                input_image, input_angle = process_image_test(new_img, raw_angle)\n",
    "                \n",
    "                images.append(input_image)\n",
    "                angles.append(input_angle)\n",
    "                \n",
    "               \n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield shuffle(X_train, y_train)\n",
    "            \n",
    "def generator_valid(samples, labels, batch_size=128, model='default'):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples, labels)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            batch_labels = labels[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for idx, val in enumerate(batch_samples):\n",
    "        \n",
    "                name = batch_samples[idx]\n",
    "                \n",
    "                path = image_path + name \n",
    "            \n",
    "                srcBGR = cv2.imread(path)\n",
    "        #        destRGB = cv2.cvtColor(srcBGR, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                new_img = cv2.cvtColor(srcBGR , cv2.COLOR_BGR2YUV)\n",
    "                          \n",
    "                raw_angle = float(batch_labels[idx])\n",
    "                \n",
    "                input_image, input_angle = process_image_test(new_img, raw_angle)\n",
    "                \n",
    "                images.append(input_image)\n",
    "                angles.append(input_angle)\n",
    "                \n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "train_valid \n",
    "- angles : streering angles, list \n",
    "- labels : image file names, list\n",
    "- model_name : model name\n",
    "  ,String\n",
    "- load_stored : whether to restore saved model or not\n",
    "  ,True or False\n",
    "- load_model_path : file path to save model\n",
    "  ,String\n",
    "- save_best : whether to save model based on Keras, ModelCheckpoint class, monitor parameter value. \n",
    "  ,True or False\n",
    "- no_epoch : number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_valid(angles, labels, model_name='default', data='default', lr=0.001, load_stored= False, load_model_path = None, save_best = False, no_epoch=5):\n",
    "    \"\"\"Load our network and our data, fit the model, save it.\"\"\"\n",
    "    \n",
    "    # select 'load model' or just 'new model'\n",
    "    \n",
    "    print(\"load_model_path is %s \" % load_model_path)\n",
    "    \n",
    "   \n",
    "    if(load_stored):\n",
    "        \n",
    "        net = load_model(load_model_path)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        if(model_name=='nvidia'):\n",
    "            net = nvidia(load=False, shape=(160, 320, 3), lr=lr)\n",
    "        \n",
    "        elif(model_name=='default'):\n",
    "            net = model(load=False, shape=(160, 320, 3), lr=lr)\n",
    "\n",
    "    \n",
    "    # select path to save model based on each model\n",
    "    if(model_name=='default'):\n",
    "        \n",
    "        save_path = load_model_path\n",
    "\n",
    "    if(model_name=='nvidia'):\n",
    "        \n",
    "        save_path = load_model_path\n",
    "    \n",
    "        \n",
    "    # select data directory \n",
    "    if(data=='default'):\n",
    "\n",
    "        X_merge = labels\n",
    "        y_merge = angles\n",
    "        pass\n",
    "    \n",
    "\n",
    "    elif(data=='recovery'):    \n",
    "        pass\n",
    "#        X_merge, y_merge = merge_data3(data_dir1,t1_re,t1_rer)\n",
    " \n",
    "\n",
    "    \n",
    "    # shuffle labels\n",
    "    X_merge,y_merge = shuffle(X_merge, y_merge)\n",
    "    \n",
    "\n",
    "    # split data\n",
    "    train_samples, validation_samples, train_labels, validation_labels = split_data(X_merge,y_merge,split = 0.1)\n",
    "  \n",
    "    \n",
    "    # define generators for training and validation\n",
    "    # image label should not be dupilcated in the label file for thread safety.\n",
    "    \n",
    "    train_generator = generator(train_samples, train_labels, batch_size=256, model=model_name)\n",
    "    validation_generator = generator_valid(validation_samples, validation_labels, batch_size=256, model=model_name)\n",
    "    \n",
    "    \n",
    "    # define whether to use checkpointer or not\n",
    "    \n",
    "    if(save_best):\n",
    "    \n",
    "        checkpointer = ModelCheckpoint(filepath=load_model_path, monitor='loss', verbose=1, \n",
    "                                   save_best_only=True,save_weights_only=False)\n",
    "        callbacks_list = [checkpointer]\n",
    "        \n",
    "        net.fit_generator(train_generator, samples_per_epoch=len(train_samples), validation_data=validation_generator, \n",
    "            nb_val_samples=len(validation_samples), nb_epoch= no_epoch,callbacks=callbacks_list)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        net.fit_generator(train_generator, samples_per_epoch=len(train_samples), validation_data=validation_generator, \n",
    "            nb_val_samples=len(validation_samples), nb_epoch= no_epoch)\n",
    "        \n",
    "        net.save(load_model_path)\n",
    "        print(\"Saved model to disk\")\n",
    "       \n",
    "    \n",
    "    # model summary for debugging\n",
    "    net.summary()\n",
    "    \n",
    "    # print weights for debugging\n",
    "    weights_test = net.get_weights()\n",
    "    \n",
    "    print(len(weights_test))\n",
    "    print((np.array(weights_test))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_model_path is ./model/test.h5 \n",
      "adam optimizer, lr is 0.001\n",
      "\n",
      " training batch shuffledEpoch 1/2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/carnd-term1/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/carnd-term1/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-18-b28b0dda8c0d>\", line 31, in generator\n",
      "    new_img = cv2.cvtColor(srcBGR , cv2.COLOR_BGR2YUV)\n",
      "cv2.error: /home/travis/miniconda/conda-bld/conda_1486587071158/work/opencv-3.1.0/modules/imgproc/src/color.cpp:8059: error: (-215) scn == 3 || scn == 4 in function cvtColor\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-75deded6ca22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_stored\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./model/test.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-d85da238f8fc>\u001b[0m in \u001b[0;36mtrain_valid\u001b[0;34m(angles, labels, model_name, data, lr, load_stored, load_model_path, save_best, no_epoch)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         net.fit_generator(train_generator, samples_per_epoch=len(train_samples), validation_data=validation_generator, \n\u001b[0;32m---> 75\u001b[0;31m             nb_val_samples=len(validation_samples), nb_epoch= no_epoch)\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1530\u001b[0m                                          \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m                                          \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1533\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "train_valid(angles = angles, labels = images, model_name='default', lr = 0.001, data= 'default', load_stored= False, load_model_path = './model/test.h5', save_best = False, no_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train_valid(angles = y_merge, labels = X_merge, model_name='default', lr = 0.001,  data= 'default', load_stored= True, load_model_path = './model/model_v4.h5', save_best = False, no_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train_valid(model_name='default_rgb',load_stored= False, load_model_path = './model/model_rgb.h5', save_best = False, no_epoch=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
